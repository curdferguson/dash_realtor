{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_list = pd.read_csv(\"data/wikipedia_msa.csv\", header=0, delimiter=\",\", encoding=\"utf-8\")\n",
    "zip_msa = pd.read_csv(\"data/zip07_cbsa06.txt\", header=0, delimiter=\",\", encoding=\"latin1\", low_memory=False)\n",
    "#print(zip_msa[zip_msa['CBSA LSAD'] == 'Metropolitan Statistical Area']['CBSA TITLE'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_list.loc[:, 'Metropolitan statistical area'] = [x.replace('?', '-').replace(' MSA', '') for x in msa_list.loc[:, 'Metropolitan statistical area']]\n",
    "\n",
    "cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Atlanta', 'Phoenix', 'Boston', 'San Francisco', 'Detroit', 'San Diego', 'Denver', 'Baltimore', 'Charlotte-', 'Orlando', 'San Antonio', 'Portland', 'Sacramento', 'Austin', 'Las Vegas', 'Cincinnati', 'Indianapolis', 'Cleveland', 'Nashville', 'Providence', 'Milwaukee', 'New Orleans', 'Hartford', 'Grand Rapids', 'Honolulu', 'Worcester', 'Greenville-', 'Sarasota', 'Boise', 'Lakeland', 'Durham', 'Spokane', 'Scranton']\n",
    "\n",
    "zcities = [zip_msa[zip_msa['CBSA TITLE'].str.contains(city, na=False)]['CBSA TITLE'].iloc[0] for city in cities]\n",
    "mcities = [msa_list[msa_list['Metropolitan statistical area'].str.contains(city, na=False)]['Metropolitan statistical area'].iloc[0] for city in cities]\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    msa_list['Metropolitan statistical area'] = [x.replace(mcities[i], zcities[i]) for x in msa_list['Metropolitan statistical area']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York-Northern New Jersey-Long Island, NY-NJ-PA  |  New York-Newark-Jersey City, NY-NJ-PA\n",
      "Los Angeles-Long Beach-Santa Ana, CA  |  Los Angeles-Long Beach-Anaheim, CA\n",
      "Chicago-Naperville-Joliet, IL-IN-WI  |  Chicago-Naperville-Elgin, IL-IN-WI\n",
      "Houston-Sugar Land-Baytown, TX  |  Houston-The Woodlands-Sugar Land, TX\n",
      "Atlanta-Sandy Springs-Marietta, GA  |  Atlanta-Sandy Springs-Alpharetta, GA\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(zcities[i], ' | ', mcities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      New York-Northern New Jersey-Long Island, NY-N...\n",
      "1                   Los Angeles-Long Beach-Santa Ana, CA\n",
      "2                    Chicago-Naperville-Joliet, IL-IN-WI\n",
      "3                        Dallas-Fort Worth-Arlington, TX\n",
      "4                         Houston-Sugar Land-Baytown, TX\n",
      "                             ...                        \n",
      "379                                         Danville, IL\n",
      "380                                      Lewiston, ID-WA\n",
      "381                                      Walla Walla, WA\n",
      "382                                             Enid, OK\n",
      "383                                      Carson City, NV\n",
      "Name: Metropolitan statistical area, Length: 384, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(msa_list[msa_list['Metropolitan statistical area'].str.contains('New York', na=False)]['Metropolitan statistical area'].iloc[0])\n",
    "print(msa_list['Metropolitan statistical area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ZIP5 STATE                      CBSA TITLE\n",
      "30530    01901    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "30531    01902    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "30532    01903    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "30533    01904    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "30534    01905    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "...        ...   ...                             ...\n",
      "2713033  01464    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "2713036  01469    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "2713037  01471    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "2713038  01472    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "2713040  01474    MA  Boston-Cambridge-Quincy, MA-NH\n",
      "\n",
      "[2472 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(zip_msa[zip_msa['CBSA TITLE'].str.contains('New York', na=False)].loc[:, ['CBSA TITLE'\n",
    "#print(len(msa_lookup[~msa_lookup.isin(zip_msa['CBSA TITLE'])]))\n",
    "#print(msa_lookup[~msa_lookup.isin(zip_msa['CBSA TITLE'])])\n",
    "msa_lookup = msa_list.loc[msa_list['Rank'] <= 100, 'Metropolitan statistical area']\n",
    "\n",
    "zip_msa1 = zip_msa[(zip_msa['CBSA TITLE'].isin(msa_lookup))]\n",
    "zip_msa1 = zip_msa1.loc[:, ['ZIP5', 'STATE', 'CBSA TITLE']]\n",
    "zip_msa1['CBSA TITLE'] = [x.replace('--', '-') for x in zip_msa1['CBSA TITLE']]\n",
    "zip_msa1['ZIP5'] = [str(i) for i in zip_msa1['ZIP5']]\n",
    "zip_msa1.loc[zip_msa1['ZIP5'].str.len() == 3, 'ZIP5'] = ['00' + i for i in zip_msa1.loc[zip_msa1['ZIP5'].str.len() == 3, 'ZIP5']]\n",
    "zip_msa1.loc[zip_msa1['ZIP5'].str.len() == 4, 'ZIP5'] = ['0' + i for i in zip_msa1.loc[zip_msa1['ZIP5'].str.len() == 4, 'ZIP5']]\n",
    "\n",
    "#print(zip_msa1['CBSA TITLE'].unique())\n",
    "#print(len(zip_msa1['CBSA TITLE'].unique()))\n",
    "#zip_msa1['ZIP5'].unique()\n",
    "\n",
    "zip_lookup = zip_msa1.loc[:, 'ZIP5']\n",
    "\n",
    "print(zip_msa1[zip_msa1['CBSA TITLE'].str.contains('Boston')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc_core = pd.read_csv(\"data/RDC_Inventory_Core_Metrics_Zip_History.csv\", header=0, delimiter=\",\", encoding=\"utf-8\", low_memory=False)\n",
    "rdc_hotness = pd.read_csv(\"data/RDC_Inventory_Hotness_Metrics_Zip_History.csv\", header=0, delimiter=\",\", encoding=\"utf-8\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099207, 40)\n",
      "201607\n",
      "(513358, 40)\n"
     ]
    }
   ],
   "source": [
    "#print(rdc_core.head(10))\n",
    "print(rdc_core.shape)\n",
    "print(rdc_core['month_date_yyyymm'].min())\n",
    "\n",
    "rdc_core = rdc_core[(rdc_core['postal_code'] != ' please contact economics@realtor.com for more details.')]\n",
    "rdc_core['month_date_yyyymm'] = rdc_core['month_date_yyyymm'].astype(int)\n",
    "\n",
    "rdc_core = rdc_core[(rdc_core['month_date_yyyymm'] >= 201901) & (rdc_core['postal_code'].isin(zip_lookup))].drop([''])\n",
    "print(rdc_core.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312905, 24)\n",
      "201901\n",
      "01001\n",
      "(312905, 24)\n",
      "01001\n"
     ]
    }
   ],
   "source": [
    "rdc_hotness.head(10)\n",
    "print(rdc_hotness.shape)\n",
    "print(rdc_hotness['month_date_yyyymm'].min())\n",
    "print(rdc_hotness['postal_code'].min())\n",
    "\n",
    "rdc_hotness = rdc_hotness[(rdc_hotness['postal_code'] != ' please contact economics@realtor.com for more details.')]\n",
    "rdc_hotness['month_date_yyyymm'] = rdc_hotness['month_date_yyyymm'].astype(int)\n",
    "rdc_hotness = rdc_hotness[(rdc_hotness['month_date_yyyymm'] >= 201901) & (rdc_hotness['postal_code'].isin(zip_lookup))]\n",
    "rdc_hotness['zip_name'].str.replace(r'\\b[a-z](?=.*,)', lambda x: x.str.capitalize(), regex=True)\n",
    "print(rdc_hotness.shape)\n",
    "print(rdc_hotness['postal_code'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_msa1.to_csv('data/zip_msa1.csv', index=False, encoding='latin1')\n",
    "rdc_hotness.to_csv('data/rdchotness.csv', index=False, encoding='utf-8')\n",
    "rdc_core.to_csv('data/rdc_core.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "5        NaN\n",
       "6        NaN\n",
       "7        NaN\n",
       "          ..\n",
       "787984   NaN\n",
       "787985   NaN\n",
       "787988   NaN\n",
       "787991   NaN\n",
       "787992   NaN\n",
       "Name: zip_name, Length: 312905, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdc_hotness['zip_name'].str.replace(r'\\b[a-z](?=.*,)', lambda x: x.str.capitalize(), regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('608final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cfae89c226e5ad68950bcaa86175219847c2b4084e678f01f50e0e32cba1cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
